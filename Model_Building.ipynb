{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('cocaine_usage_ml': conda)"
  },
  "interpreter": {
   "hash": "5dad09899fc842894502123f22779136d8d943630f6ef1cc7129ea1cb28afa36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting if Someone has Tried Cocaine\n",
    "## Model Building"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\r\n",
    "\r\n",
    "Before we can use our data to train models, we need to do a few things:\r\n",
    "\r\n",
    "1. Select our desired features\r\n",
    "\r\n",
    "2. Use SimpleImputer to replace NaN values with the mean of that column\r\n",
    "\r\n",
    "3. Apply standard scaling to our numerical variables\r\n",
    "\r\n",
    "4. Dummify/One Hot Encode our categorical variables\r\n",
    "\r\n",
    "We begin with removing year, irwrkstat, cocever, and crkever columns. These columns were only used for EDA, feature engineering, or are redundant."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read in pickled data, and drop unneeded columns\r\n",
    "df = pd.read_pickle(\"./pickle/NSDUH_target_dropna_2016-2019.pkl\")\r\n",
    "df = df.drop(['cocever', 'crkever', 'year', 'irwrkstat'], axis=1)\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        cig30use  iralcfy  irmjfy  irherfy  irmethamyfq  health  irsex  \\\n",
       "0            0.0        5       0        0            0     2.0      1   \n",
       "1            0.0       52     364        0            0     1.0      1   \n",
       "2            0.0       48       0        0            0     2.0      0   \n",
       "3            0.0        2       0        0            0     3.0      0   \n",
       "4           22.0        6       0        0            0     3.0      0   \n",
       "...          ...      ...     ...      ...          ...     ...    ...   \n",
       "282763       0.0      104       2        0            0     2.0      0   \n",
       "282764       0.0       10       0        0            0     2.0      0   \n",
       "282765       0.0        0       0        0            0     2.0      1   \n",
       "282766       0.0        1       0        0            0     2.0      0   \n",
       "282767       0.0        0       0        0            0     1.0      1   \n",
       "\n",
       "        ireduhighst2  catag3  wrkdhrswk2  irhhsiz2  irki17_2  irpinc3  \\\n",
       "0                  7       1         0.0         1         2        1   \n",
       "1                  8       4        40.0         4         3        2   \n",
       "2                 11       3         0.0         1         1        1   \n",
       "3                  4       1         NaN         5         4        1   \n",
       "4                  9       2         0.0         4         3        1   \n",
       "...              ...     ...         ...       ...       ...      ...   \n",
       "282763             9       2        40.0         2         1        3   \n",
       "282764            11       3        26.0         2         1        2   \n",
       "282765             4       1         NaN         6         3        1   \n",
       "282766            11       1         0.0         6         4        1   \n",
       "282767             5       1         NaN         6         4        1   \n",
       "\n",
       "        coccrkever  \n",
       "0              0.0  \n",
       "1              1.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "282763         0.0  \n",
       "282764         0.0  \n",
       "282765         0.0  \n",
       "282766         0.0  \n",
       "282767         0.0  \n",
       "\n",
       "[282768 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cig30use</th>\n",
       "      <th>iralcfy</th>\n",
       "      <th>irmjfy</th>\n",
       "      <th>irherfy</th>\n",
       "      <th>irmethamyfq</th>\n",
       "      <th>health</th>\n",
       "      <th>irsex</th>\n",
       "      <th>ireduhighst2</th>\n",
       "      <th>catag3</th>\n",
       "      <th>wrkdhrswk2</th>\n",
       "      <th>irhhsiz2</th>\n",
       "      <th>irki17_2</th>\n",
       "      <th>irpinc3</th>\n",
       "      <th>coccrkever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282764</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282765</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282766</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282768 rows Ã— 14 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we must separate our numerical and categorical variables. Numerical variables will be adjusted per column by StandardScaler(), which converts the data such that the mean and standard deviation is 0 and 1 for that column, respectively. This standardization across numerical variables increases our model's accuracy.\r\n",
    "\r\n",
    "As for categorical variables, each unique value in a categorical column must be given its own separate, binary column indicating if that observation fits that unique value or not. We do this because keeping them in one column implies some kind of order. Something like gender makes no sense to order, and is therefore a candidate to be separated into different columns (dummified). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Continuous variables\r\n",
    "num_cols = [\r\n",
    "    \"iralcfy\",\r\n",
    "    \"catag3\",\r\n",
    "    \"health\",\r\n",
    "    \"ireduhighst2\",\r\n",
    "    \"irpinc3\",\r\n",
    "    \"irki17_2\",\r\n",
    "    \"irmjfy\",\r\n",
    "    \"wrkdhrswk2\",\r\n",
    "    'irhhsiz2',\r\n",
    "    'cig30use',\r\n",
    "    'irherfy',\r\n",
    "    'irmethamyfq'\r\n",
    "]\r\n",
    "\r\n",
    "num_indexes = [i for i in range(12)]\r\n",
    "\r\n",
    "# Categorical variables\r\n",
    "cat_cols = ['irsex']\r\n",
    "\r\n",
    "cat_indexes = [12]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating our Column Transformer for our Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
    "from sklearn.compose import ColumnTransformer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create a preprocessor from ColumnTransformer.\r\n",
    "# StandardScaler() applied to num_cols, and OneHotEncoder() applied to cat_cols\r\n",
    "# We specify cols with indices because column names will be removed when as apply\r\n",
    "# our transformer to a pipeline.\r\n",
    "preprocessor = ColumnTransformer(transformers=[\r\n",
    "    ('num', StandardScaler(), num_indexes),\r\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_indexes)\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Building\r\n",
    "\r\n",
    "Now that our data is properly processed, we can test several models across different hyperparameters using GridSearchCV. We will be testing the following models:\r\n",
    "\r\n",
    "1. RandomForestClassifier()\r\n",
    "\r\n",
    "2. LogisticRegression()\r\n",
    "\r\n",
    "3. svm.LinearSVC()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Define feature and target columns\r\n",
    "features = num_cols+cat_cols\r\n",
    "target = \"coccrkever\"\r\n",
    "\r\n",
    "# Standard naming conventions for feature/test datasets\r\n",
    "X = df[features]\r\n",
    "y = df[target]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Parameter grid for GridSearchCV\r\n",
    "model_grid = {\r\n",
    "    'random_forest': {\r\n",
    "        'model':RandomForestClassifier(random_state=15, n_jobs=3, n_estimators=500),\r\n",
    "        'params': {\r\n",
    "            'estimator__max_depth': [11, 12, 13, 14],\r\n",
    "            'estimator__criterion':['gini', 'entropy']\r\n",
    "        }\r\n",
    "    },\r\n",
    "    'logistic_regression': {\r\n",
    "        'model': LogisticRegression(random_state=15, n_jobs=3),\r\n",
    "        'params': {\r\n",
    "            'estimator__C': [0.085, 0.09, 0.092],\r\n",
    "            'estimator__solver':['lbfgs', 'liblinear'],\r\n",
    "        }\r\n",
    "    },\r\n",
    "    'svm': {\r\n",
    "        'model': svm.LinearSVC(random_state=15, max_iter=100000),\r\n",
    "        'params': {\r\n",
    "            'estimator__C':[0.52, 0.55, 0.6, 0.65]\r\n",
    "        }\r\n",
    "    }\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our dataset still has NaN values in it, but we need to be careful about how we impute missing information in our GridSearchCV. If we ran our imputer on the whole dataset, our imputer would be fitted with data that will become test data, which would result in data leakage. So, we should only fit our imputer based on the training data.\r\n",
    "\r\n",
    "K-cross fold validation will be used throughout the GridSearchCV, which can take a pipeline as its estimator. Our pipeline will include a SimpleImputer that default imputes with the mean and replaces np.nan values. By doing it this way, our SimpleImputer() is only trained on training folds, and any test NaN values are imputed based on the training data. We also include a FunctionTransformer that rounds off imputed data, as our data has only used whole numbers up to this point."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# List to hold model scores\r\n",
    "scores = []\r\n",
    "\r\n",
    "for model_name, model_params in model_grid.items():\r\n",
    "    # Create our pipeline\r\n",
    "    pipe = Pipeline(steps=[\r\n",
    "        ('impute', SimpleImputer()),\r\n",
    "        ('round', FunctionTransformer(np.round)),\r\n",
    "        ('preprocessor', preprocessor),\r\n",
    "        ('estimator', model_params['model'])\r\n",
    "    ])\r\n",
    "\r\n",
    "    model = GridSearchCV(estimator=pipe, param_grid=model_params['params'], cv=4, return_train_score=False, refit=True)\r\n",
    "    model.fit(X, y)\r\n",
    "    scores.append({\r\n",
    "        'model': model_name,\r\n",
    "        'best_score:': model.best_score_,\r\n",
    "        'best_params': model.best_params_\r\n",
    "    })"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\envs\\cocaine_usage_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Show scores as df\r\n",
    "scores"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'model': 'random_forest',\n",
       "  'best_score:': 0.8974318168958297,\n",
       "  'best_params': {'estimator__criterion': 'gini', 'estimator__max_depth': 12}},\n",
       " {'model': 'logistic_regression',\n",
       "  'best_score:': 0.8909777626888473,\n",
       "  'best_params': {'estimator__C': 0.085, 'estimator__solver': 'liblinear'}},\n",
       " {'model': 'svm',\n",
       "  'best_score:': 0.8904366830758784,\n",
       "  'best_params': {'estimator__C': 0.52}}]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choosing a Model\n",
    "\n",
    "Although our random forest model has the highest accuracy, the accuracies are very similar. Let's train a model using the best hyperparameters of each, then look at the classification report of each model to gain better insight into the performance of each model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.25, random_state=12)\r\n",
    "\r\n",
    "pipe = Pipeline(steps=[\r\n",
    "        ('impute', SimpleImputer()),\r\n",
    "        ('round', FunctionTransformer(np.round)),\r\n",
    "        ('preprocessor', preprocessor)\r\n",
    "    ])\r\n",
    "\r\n",
    "X_train = pipe.fit_transform(X_train, y_train)\r\n",
    "X_test = pipe.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we train any of our models, we need to create a baseline model for our classifier. Our goal is to successfully predict if someone has used cocaine or not. So, our dummy classifier would simply work by constantly classifying an observation as \"Yes, has tried cocaine.\" We can calculate this dummy model accuracy by simply dividing the number of \"1\" in our y_test by the length of y_test.\r\n",
    "\r\n",
    "This would result in 100% recall (everyone who has used cocaine was predicted correctly) but with horrendous precision (~12% of \"Yes\" predictions were correct). If we wanted to make a guess about someone having had used cocaine before, we want to be as precise as possible, even if it is at the cost of recall."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(\"Dummy Model Score: \", y_test[y_test==1].sum()/y_test.shape[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dummy Model Score:  0.11782096984100039\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Train a model for each model type using our best hyperparameters. This is so we can analyze each\r\n",
    "# in a classification report\r\n",
    "\r\n",
    "rf = RandomForestClassifier(random_state=15, n_jobs=3, n_estimators=500, max_depth=12, criterion='gini')\r\n",
    "rf.fit(X_train, y_train)\r\n",
    "\r\n",
    "lg = LogisticRegression(random_state=15, solver='liblinear',C=0.085)\r\n",
    "lg.fit(X_train, y_train)\r\n",
    "\r\n",
    "lsvc = svm.LinearSVC(random_state=15, max_iter=100000, C=0.52)\r\n",
    "lsvc.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(C=0.52, max_iter=100000, random_state=15)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "rf_predict = rf.predict(X_test)\r\n",
    "lg_predict = lg.predict(X_test)\r\n",
    "lsvc_predict = lsvc.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(\"Random Forest Score: %f\\nLogistic Regression Score: %f\\nLinear SVC Score: %f\\n\" %(accuracy_score(y_test, rf_predict), accuracy_score(y_test, lg_predict), accuracy_score(y_test, lsvc_predict)))\r\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, rf_predict))\r\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, lg_predict))\r\n",
    "print(\"Linear SVC:\\n\", classification_report(y_test, lsvc_predict))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest Score: 0.898051\n",
      "Logistic Regression Score: 0.891232\n",
      "Linear SVC Score: 0.890794\n",
      "\n",
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.94     62363\n",
      "         1.0       0.68      0.25      0.37      8329\n",
      "\n",
      "    accuracy                           0.90     70692\n",
      "   macro avg       0.80      0.62      0.66     70692\n",
      "weighted avg       0.88      0.90      0.88     70692\n",
      "\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     62363\n",
      "         1.0       0.62      0.20      0.30      8329\n",
      "\n",
      "    accuracy                           0.89     70692\n",
      "   macro avg       0.76      0.59      0.62     70692\n",
      "weighted avg       0.87      0.89      0.87     70692\n",
      "\n",
      "Linear SVC:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.99      0.94     62363\n",
      "         1.0       0.65      0.16      0.26      8329\n",
      "\n",
      "    accuracy                           0.89     70692\n",
      "   macro avg       0.77      0.57      0.60     70692\n",
      "weighted avg       0.87      0.89      0.86     70692\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accuracy vs Precision vs Recall\r\n",
    "\r\n",
    "Although the random forest performed the best in terms of total accuracy, our linear SVC model has the highest precision of each model. Recall teh differences between accuracy, precision, and recall:\r\n",
    "\r\n",
    "1. **Accuracy**: Proportion of correct predictions from total observations\r\n",
    "\r\n",
    "2. **Precision**: For a given class, the proportion of correct predictions from total predictions\r\n",
    "\r\n",
    "3. **Recall**: For a given class, proportion of correct predictions from the total number of true observations for that class\r\n",
    "\r\n",
    "Our models have low recall. That means we miss a large number of people who have actually used cocaine. However, we also have extremely high precision. This means that for the people we *do* predict have used cocaine, we are actually correct! This is important to consider. If your goal is to either help people using cocaine or prevent people from becoming addicted cocaine, it would be very bad to wrongly approach someone believing they've tried cocaine when they actually have not. **To prevent false positives, we will choose our Random Forest Classifier because it has the highest precision.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving our Data\n",
    "Although we've decided on using the linear SVC model, we will save all the models regardless, just in case we want them in the future."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Pickle models for later\r\n",
    "for model, name in zip([lg, lsvc], [\"logreg_model\", \"lsvc_model\"]):\r\n",
    "    with open(\"model/\" + name + \".pickle\", 'wb') as f:\r\n",
    "        pickle.dump(model, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import gzip, pickletools\r\n",
    "\r\n",
    "# The output of a regular pickle.dump for our random forest is quite large,\r\n",
    "# we can compress it using gzip\r\n",
    "with gzip.open(\"model/randforest_model.pickle\", \"wb\") as f:\r\n",
    "    pickled = pickle.dumps(rf)\r\n",
    "    optimized_pickle = pickletools.optimize(pickled)\r\n",
    "    f.write(optimized_pickle)\r\n",
    "\r\n",
    "\"\"\"Code for loading from a gzipped pickle file\"\"\"\r\n",
    "# with gzip.open(\"model/randforest_model_optimized.pickle\", 'rb') as f:\r\n",
    "#     p = pickle.Unpickler(f)\r\n",
    "#     rf = p.load()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Code for loading from a gzipped pickle file'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to save our fitted pipeline to transform future data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Pickle our Random Forest Classifier\r\n",
    "with open(\"model/pipeline.pickle\", 'wb') as f:\r\n",
    "        pickle.dump(pipe, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's save our columns as a JSON file for future reference."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import json\r\n",
    "\r\n",
    "# Firstly we append our data columns to the json\r\n",
    "column_info = {\r\n",
    "    'data_columns' : [col for col in num_cols+cat_cols]\r\n",
    "}\r\n",
    "\r\n",
    "# col_desc is a tab separated text file created separately that contains information for each column\r\n",
    "# We'll be sending back this json for users to read with our server, so this information will be helpful\r\n",
    "col_desc = pd.read_csv('model/col_desc.txt', header=0, sep='\\t')\r\n",
    "for row in range(col_desc.shape[0]):\r\n",
    "    column_info[col_desc.iloc[row, 0]] = col_desc.iloc[row, 1]\r\n",
    "\r\n",
    "# Write dict to a json file\r\n",
    "with open(\"model/data_columns.json\", \"w\") as f:\r\n",
    "    f.write(json.dumps(column_info))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can move on to creating a server where we can make our model easily interactable."
   ],
   "metadata": {}
  }
 ]
}