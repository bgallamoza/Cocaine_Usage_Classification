{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "39d0725753d0ad0b2b78de10b3b7451c8aa9b3c904c7c1796a98e42af75eb3a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting if Someone has Tried Cocaine\n",
    "## Model Building"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Before we can use our data to train models, we need to do a few things:\n",
    "\n",
    "1. Select our desired features\n",
    "\n",
    "2. Apply standard scaling to our numerical variables\n",
    "\n",
    "3. Dummify/One Hot Encode our categorical variables\n",
    "\n",
    "We begin with removing coutyp4, year, irwrkstat, and mjever columns. These columns were only used for EDA or do not seem to provide insight in target prediction."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read in pickled data, and drop unneeded columns\r\n",
    "df = pd.read_pickle(\"./pickle/NSDUH_cleaned_dropna_2016-2019.pkl\")\r\n",
    "df = df.drop(['cocever', 'crkever', 'year'], axis=1)\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        cig30use  iralcfy  irmjfy  irherfy  irmethamyfq  health  irsex  \\\n",
       "0            0.0        5       0        0            0     2.0      1   \n",
       "1            0.0       52     364        0            0     1.0      1   \n",
       "2            0.0       48       0        0            0     2.0      0   \n",
       "4           22.0        6       0        0            0     3.0      0   \n",
       "5            0.0      120       0        0            0     3.0      1   \n",
       "...          ...      ...     ...      ...          ...     ...    ...   \n",
       "282760       0.0        0       0        0            0     1.0      1   \n",
       "282762       0.0        0       0        0            0     3.0      1   \n",
       "282763       0.0      104       2        0            0     2.0      0   \n",
       "282764       0.0       10       0        0            0     2.0      0   \n",
       "282766       0.0        1       0        0            0     2.0      0   \n",
       "\n",
       "        ireduhighst2  catag3  newrace2  wrkdhrswk2  irhhsiz2  irki17_2  \\\n",
       "0                  7       1         1         0.0         1         2   \n",
       "1                  8       4         7        40.0         4         3   \n",
       "2                 11       3         1         0.0         1         1   \n",
       "4                  9       2         1         0.0         4         3   \n",
       "5                  9       2         5         0.0         2         1   \n",
       "...              ...     ...       ...         ...       ...       ...   \n",
       "282760             8       4         1         0.0         3         1   \n",
       "282762             1       4         7         0.0         3         1   \n",
       "282763             9       2         7        40.0         2         1   \n",
       "282764            11       3         5        26.0         2         1   \n",
       "282766            11       1         7         0.0         6         4   \n",
       "\n",
       "        irpinc3  coccrkever  \n",
       "0             1         0.0  \n",
       "1             2         1.0  \n",
       "2             1         0.0  \n",
       "4             1         0.0  \n",
       "5             1         0.0  \n",
       "...         ...         ...  \n",
       "282760        1         0.0  \n",
       "282762        3         0.0  \n",
       "282763        3         0.0  \n",
       "282764        2         0.0  \n",
       "282766        1         0.0  \n",
       "\n",
       "[226977 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cig30use</th>\n",
       "      <th>iralcfy</th>\n",
       "      <th>irmjfy</th>\n",
       "      <th>irherfy</th>\n",
       "      <th>irmethamyfq</th>\n",
       "      <th>health</th>\n",
       "      <th>irsex</th>\n",
       "      <th>ireduhighst2</th>\n",
       "      <th>catag3</th>\n",
       "      <th>newrace2</th>\n",
       "      <th>wrkdhrswk2</th>\n",
       "      <th>irhhsiz2</th>\n",
       "      <th>irki17_2</th>\n",
       "      <th>irpinc3</th>\n",
       "      <th>coccrkever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282762</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282764</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282766</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226977 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we must separate our numerical and categorical variables. Numerical variables will be adjusted per column by StandardScaler(), which converts the data such that the mean and standard deviation is 0 and 1 for that column, respectively. This standardization across numerical variables increases our model's accuracy.\n",
    "\n",
    "As for categorical variables, each unique value in a categorical column must be given its own separate, binary column indicating if that observation fits that unique value or not. We do this because keeping them in one column implies some kind of order. Something like race (newrace2 column) makes no sense to order, and is therefore a candidate to be separated into different columns (dummified). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Continuous variables\r\n",
    "num_cols = [\r\n",
    "    \"iralcfy\",\r\n",
    "    \"catag3\",\r\n",
    "    \"health\",\r\n",
    "    \"ireduhighst2\",\r\n",
    "    \"irpinc3\",\r\n",
    "    \"irki17_2\",\r\n",
    "    \"irmjfy\",\r\n",
    "    \"wrkdhrswk2\",\r\n",
    "    'irhhsiz2',\r\n",
    "    'cig30use',\r\n",
    "    'irherfy',\r\n",
    "    'irmethamyfq'\r\n",
    "]\r\n",
    "\r\n",
    "# Categorical variables\r\n",
    "cat_cols = [\r\n",
    "    \"newrace2\",\r\n",
    "    \"irsex\"\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing with Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
    "from sklearn.compose import ColumnTransformer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create a preprocessor from ColumnTransformer\r\n",
    "# StandardScaler() applied to num_cols, and OneHotEncoder() applied to cat_cols\r\n",
    "preprocessor = ColumnTransformer(transformers=[\r\n",
    "    ('num', StandardScaler(), num_cols),\r\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_cols)\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Building\n",
    "\n",
    "Now that our data is properly processed, we can test several models across different hyperparameters using GridSearchCV. We will be testing the following models:\n",
    "\n",
    "1. RandomForestClassifier()\n",
    "\n",
    "2. LogisticRegression()\n",
    "\n",
    "3. svm.LinearSVC()\n",
    "\n",
    "*We will only test the default hyperparamters for our LinearSVC due to the length of time required to train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Define feature and target columns\r\n",
    "features = num_cols+cat_cols\r\n",
    "target = \"coccrkever\"\r\n",
    "\r\n",
    "# Standard naming conventions for feature/test datasets\r\n",
    "X = df[features]\r\n",
    "y = df[target]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\r\n",
    "    ('num', StandardScaler(), num_cols),\r\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_cols)\r\n",
    "])\r\n",
    "\r\n",
    "# Parameter grid for GridSearchCV\r\n",
    "model_grid = {\r\n",
    "    'random_forest': {\r\n",
    "        'model':RandomForestClassifier(random_state=15, n_jobs=3, n_estimators=500),\r\n",
    "        'params': {\r\n",
    "            'estimator__max_depth': [11, 12, 13, 14],\r\n",
    "            'estimator__criterion':['gini', 'entropy']\r\n",
    "        }\r\n",
    "    },\r\n",
    "    'logistic_regression': {\r\n",
    "        'model': LogisticRegression(random_state=15, n_jobs=3),\r\n",
    "        'params': {\r\n",
    "            'estimator__C': [0.085, 0.09, 0.092],\r\n",
    "            'estimator__solver':['lbfgs', 'liblinear'],\r\n",
    "        }\r\n",
    "    },\r\n",
    "    'svm': {\r\n",
    "        'model': svm.LinearSVC(random_state=15, max_iter=100000),\r\n",
    "        'params': {\r\n",
    "            'estimator__C':[0.52, 0.55, 0.6, 0.65]\r\n",
    "        }\r\n",
    "    }\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# List to hold model scores\r\n",
    "scores = []\r\n",
    "\r\n",
    "for model_name, model_params in model_grid.items():\r\n",
    "    pipe = Pipeline(steps=[\r\n",
    "        ('preprocessor', preprocessor),\r\n",
    "        ('estimator', model_params['model'])\r\n",
    "    ])\r\n",
    "\r\n",
    "    model = GridSearchCV(estimator=pipe, param_grid=model_params['params'], cv=4, return_train_score=False, refit=True)\r\n",
    "    model.fit(X, y)\r\n",
    "    scores.append({\r\n",
    "        'model': model_name,\r\n",
    "        'best_score:': model.best_score_,\r\n",
    "        'best_params': model.best_params_\r\n",
    "    })"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\Brennan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Show scores as df\r\n",
    "scores"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'model': 'random_forest',\n",
       "  'best_score:': 0.8858342496707732,\n",
       "  'best_params': {'estimator__criterion': 'entropy',\n",
       "   'estimator__max_depth': 14}},\n",
       " {'model': 'logistic_regression',\n",
       "  'best_score:': 0.8781065916890805,\n",
       "  'best_params': {'estimator__C': 0.085, 'estimator__solver': 'liblinear'}},\n",
       " {'model': 'svm',\n",
       "  'best_score:': 0.877463356611295,\n",
       "  'best_params': {'estimator__C': 0.52}}]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choosing a Model\n",
    "\n",
    "Although our random forest model has the highest accuracy, the accuracies are very similar. Let's train a model using the best hyperparameters of each, then look at the classification report of each model to gain better insight into the performance of each model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.25, random_state=12)\r\n",
    "\r\n",
    "preprocessor = ColumnTransformer(transformers=[\r\n",
    "    ('num', StandardScaler(), num_cols),\r\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_cols)\r\n",
    "])\r\n",
    "\r\n",
    "pipe = Pipeline(steps=[\r\n",
    "        ('preprocessor', preprocessor),\r\n",
    "    ])\r\n",
    "\r\n",
    "X_train = pipe.fit_transform(X_train)\r\n",
    "X_test = pipe.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Train a model for each model type using our best hyperparameters. This is so we can analyze each\r\n",
    "# in a classification report\r\n",
    "\r\n",
    "rf = RandomForestClassifier(random_state=15, n_jobs=3, n_estimators=500, max_depth=14, criterion='entropy')\r\n",
    "rf.fit(X_train, y_train)\r\n",
    "\r\n",
    "lg = LogisticRegression(random_state=15, solver='liblinear',C=0.085)\r\n",
    "lg.fit(X_train, y_train)\r\n",
    "\r\n",
    "lsvc = svm.LinearSVC(random_state=15, max_iter=100000, C=0.52)\r\n",
    "lsvc.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(C=0.52, max_iter=100000, random_state=15)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "rf_predict = rf.predict(X_test)\r\n",
    "lg_predict = lg.predict(X_test)\r\n",
    "lsvc_predict = lsvc.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "print(\"Random Forest Score: %f\\nLogistic Regression Score: %f\\nLinear SVC Score: %f\\n\" %(accuracy_score(y_test, rf_predict), accuracy_score(y_test, lg_predict), accuracy_score(y_test, lsvc_predict)))\r\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, rf_predict))\r\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, lg_predict))\r\n",
    "print(\"Linear SVC:\\n\", classification_report(y_test, lsvc_predict))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest Score: 0.885276\n",
      "Logistic Regression Score: 0.877187\n",
      "Linear SVC Score: 0.876764\n",
      "\n",
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     49154\n",
      "         1.0       0.68      0.27      0.39      7591\n",
      "\n",
      "    accuracy                           0.89     56745\n",
      "   macro avg       0.79      0.63      0.66     56745\n",
      "weighted avg       0.87      0.89      0.86     56745\n",
      "\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93     49154\n",
      "         1.0       0.63      0.20      0.31      7591\n",
      "\n",
      "    accuracy                           0.88     56745\n",
      "   macro avg       0.76      0.59      0.62     56745\n",
      "weighted avg       0.85      0.88      0.85     56745\n",
      "\n",
      "Linear SVC:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93     49154\n",
      "         1.0       0.66      0.17      0.26      7591\n",
      "\n",
      "    accuracy                           0.88     56745\n",
      "   macro avg       0.77      0.58      0.60     56745\n",
      "weighted avg       0.85      0.88      0.84     56745\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accuracy vs Precision vs Recall\r\n",
    "\r\n",
    "Although the random forest performed the best in terms of total accuracy, our linear SVC model has the highest precision of each model. Recall teh differences between accuracy, precision, and recall:\r\n",
    "\r\n",
    "1. **Accuracy**: Proportion of correct predictions from total observations\r\n",
    "\r\n",
    "2. **Precision**: For a given class, the proportion of correct predictions from total predictions\r\n",
    "\r\n",
    "3. **Recall**: For a given class, proportion of correct predictions from the total number of true observations for that class\r\n",
    "\r\n",
    "Our models have low recall. That means we miss a large number of people who have actually used cocaine. However, we also have extremely high precision. This means that for the people we *do* predict have used cocaine, we are actually correct! This is important to consider. If your goal is to either help people using cocaine or prevent people from becoming addicted cocaine, it would be very bad to wrongly approach someone believing they've tried cocaine when they actually have not. **To prevent false positives, we will choose our Random Forest Classifier because it has the highest precision.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving our Data\n",
    "Although we've decided on using the linear SVC model, we will save all the models regardless, just in case we want them in the future."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Pickle models for later\r\n",
    "for model, name in zip([lg, lsvc], [\"logreg_model\", \"lsvc_model\"]):\r\n",
    "    with open(\"model/\" + name + \".pickle\", 'wb') as f:\r\n",
    "        pickle.dump(model, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import gzip, pickletools\r\n",
    "\r\n",
    "# The output of a regular pickle.dump for our random forest is quite large,\r\n",
    "# we can compress it using gzip\r\n",
    "with gzip.open(\"model/randforest_model.pickle\", \"wb\") as f:\r\n",
    "    pickled = pickle.dumps(rf)\r\n",
    "    optimized_pickle = pickletools.optimize(pickled)\r\n",
    "    f.write(optimized_pickle)\r\n",
    "\r\n",
    "\"\"\"Code for loading from a gzipped pickle file\"\"\"\r\n",
    "# with gzip.open(\"model/randforest_model_optimized.pickle\", 'rb') as f:\r\n",
    "#     p = pickle.Unpickler(f)\r\n",
    "#     rf = p.load()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Code for loading from a gzipped pickle file'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to save our fitted pipeline to transform future data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Pickle our Random Forest Classifier\r\n",
    "with open(\"model/pipeline.pickle\", 'wb') as f:\r\n",
    "        pickle.dump(pipe, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's save our columns as a JSON file for future reference."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import json\r\n",
    "\r\n",
    "# Firstly we append our data columns to the json\r\n",
    "column_info = {\r\n",
    "    'data_columns' : [col for col in num_cols+cat_cols]\r\n",
    "}\r\n",
    "\r\n",
    "# col_desc is a tab separated text file created separately that contains information for each column\r\n",
    "# We'll be sending back this json for users to read with our server, so this information will be helpful\r\n",
    "col_desc = pd.read_csv('model/col_desc.txt', header=0, sep='\\t')\r\n",
    "for row in range(col_desc.shape[0]):\r\n",
    "    column_info[col_desc.iloc[row, 0]] = col_desc.iloc[row, 1]\r\n",
    "\r\n",
    "# Write dict to a json file\r\n",
    "with open(\"model/data_columns.json\", \"w\") as f:\r\n",
    "    f.write(json.dumps(column_info))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can move on to creating a server where we can make our model easily interactable."
   ],
   "metadata": {}
  }
 ]
}